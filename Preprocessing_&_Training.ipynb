{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing & Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJxSgdFF1H7f3GFHo+YM9T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martell-n-tardy/Risk-Prediction-Models-for-Type-2-Diabetes/blob/main/Preprocessing_%26_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLGBKdYiOsV6"
      },
      "source": [
        "# **Preprocessing & Training: BRFSS data - By Martell Tardy, M.S.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv63x9d1O9MI"
      },
      "source": [
        "# Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTS0zy33N1mO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import mean,std\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpf74NDyPZlt"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ommBzFBYPaMG",
        "outputId": "f968d895-b772-4721-caac-229bbe9eda17"
      },
      "source": [
        "#mount Drive and grant access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm6o8qvd96L8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "8eddde02-1ad6-4a2b-e31b-770eab466457"
      },
      "source": [
        "#read in data and save as variable df\n",
        "df = pd.read_csv('/content/drive/MyDrive/SPRINGBOARD/CAPSTONE 3/BRFSS Data/Processed/finalfeats_2015.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>prediabetes</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>blood_pressure_meds</th>\n",
              "      <th>general_health</th>\n",
              "      <th>fruit_juice</th>\n",
              "      <th>pneumonia_shot</th>\n",
              "      <th>race</th>\n",
              "      <th>cholesterol_check</th>\n",
              "      <th>high_cholesterol</th>\n",
              "      <th>height</th>\n",
              "      <th>cognitive_decline</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>fruit</th>\n",
              "      <th>kidney_health</th>\n",
              "      <th>physical_health</th>\n",
              "      <th>sex</th>\n",
              "      <th>shingles_vaccine</th>\n",
              "      <th>other_veg</th>\n",
              "      <th>green_veg</th>\n",
              "      <th>cigarettes</th>\n",
              "      <th>employment</th>\n",
              "      <th>sodium</th>\n",
              "      <th>type2_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.169308</td>\n",
              "      <td>0.074352</td>\n",
              "      <td>0.171900</td>\n",
              "      <td>0.230504</td>\n",
              "      <td>0.266355</td>\n",
              "      <td>0.296992</td>\n",
              "      <td>0.112202</td>\n",
              "      <td>0.212869</td>\n",
              "      <td>0.119337</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.225517</td>\n",
              "      <td>0.128326</td>\n",
              "      <td>0.111739</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.128318</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.214877</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.127072</td>\n",
              "      <td>0.097530</td>\n",
              "      <td>0.292054</td>\n",
              "      <td>0.125268</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.169308</td>\n",
              "      <td>0.074352</td>\n",
              "      <td>0.113065</td>\n",
              "      <td>0.115439</td>\n",
              "      <td>0.053195</td>\n",
              "      <td>0.089652</td>\n",
              "      <td>0.112202</td>\n",
              "      <td>0.076920</td>\n",
              "      <td>0.119337</td>\n",
              "      <td>0.027878</td>\n",
              "      <td>0.083594</td>\n",
              "      <td>0.128326</td>\n",
              "      <td>0.264431</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.128318</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.094261</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.127072</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.134980</td>\n",
              "      <td>0.098757</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.169308</td>\n",
              "      <td>0.074352</td>\n",
              "      <td>0.218709</td>\n",
              "      <td>0.056077</td>\n",
              "      <td>0.053195</td>\n",
              "      <td>0.296992</td>\n",
              "      <td>0.122087</td>\n",
              "      <td>0.119395</td>\n",
              "      <td>0.119337</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.225517</td>\n",
              "      <td>0.122700</td>\n",
              "      <td>0.111739</td>\n",
              "      <td>0.113072</td>\n",
              "      <td>0.123805</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.214877</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.125341</td>\n",
              "      <td>0.123034</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.200757</td>\n",
              "      <td>0.125268</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.169308</td>\n",
              "      <td>0.074352</td>\n",
              "      <td>0.171900</td>\n",
              "      <td>0.115439</td>\n",
              "      <td>0.266355</td>\n",
              "      <td>0.296992</td>\n",
              "      <td>0.153444</td>\n",
              "      <td>0.212869</td>\n",
              "      <td>0.119337</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.225517</td>\n",
              "      <td>0.128326</td>\n",
              "      <td>0.264431</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.128318</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.277691</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.127072</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.292054</td>\n",
              "      <td>0.098757</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.169308</td>\n",
              "      <td>0.074352</td>\n",
              "      <td>0.171900</td>\n",
              "      <td>0.056077</td>\n",
              "      <td>0.053195</td>\n",
              "      <td>0.296992</td>\n",
              "      <td>0.122087</td>\n",
              "      <td>0.212869</td>\n",
              "      <td>0.119337</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.083594</td>\n",
              "      <td>0.128326</td>\n",
              "      <td>0.164604</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.128318</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.256335</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.127072</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.292054</td>\n",
              "      <td>0.198241</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441451</th>\n",
              "      <td>0.201110</td>\n",
              "      <td>0.151725</td>\n",
              "      <td>0.218709</td>\n",
              "      <td>0.043446</td>\n",
              "      <td>0.266355</td>\n",
              "      <td>0.296992</td>\n",
              "      <td>0.112202</td>\n",
              "      <td>0.076920</td>\n",
              "      <td>0.140718</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.225517</td>\n",
              "      <td>0.128326</td>\n",
              "      <td>0.164604</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.147174</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.094261</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.175943</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.200757</td>\n",
              "      <td>0.198241</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441452</th>\n",
              "      <td>0.201110</td>\n",
              "      <td>0.151725</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.115439</td>\n",
              "      <td>0.053195</td>\n",
              "      <td>0.089652</td>\n",
              "      <td>0.112202</td>\n",
              "      <td>0.076920</td>\n",
              "      <td>0.140718</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.083594</td>\n",
              "      <td>0.128326</td>\n",
              "      <td>0.111739</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.128318</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.094261</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.127072</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.070031</td>\n",
              "      <td>0.198241</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441453</th>\n",
              "      <td>0.201110</td>\n",
              "      <td>0.151725</td>\n",
              "      <td>0.218709</td>\n",
              "      <td>0.230504</td>\n",
              "      <td>0.266355</td>\n",
              "      <td>0.296992</td>\n",
              "      <td>0.122087</td>\n",
              "      <td>0.119395</td>\n",
              "      <td>0.140718</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.225517</td>\n",
              "      <td>0.128326</td>\n",
              "      <td>0.111739</td>\n",
              "      <td>0.093876</td>\n",
              "      <td>0.123805</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.094261</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.125341</td>\n",
              "      <td>0.123034</td>\n",
              "      <td>0.189050</td>\n",
              "      <td>0.200757</td>\n",
              "      <td>0.125268</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441454</th>\n",
              "      <td>0.201110</td>\n",
              "      <td>0.151725</td>\n",
              "      <td>0.113065</td>\n",
              "      <td>0.056077</td>\n",
              "      <td>0.266355</td>\n",
              "      <td>0.089652</td>\n",
              "      <td>0.112202</td>\n",
              "      <td>0.076920</td>\n",
              "      <td>0.140718</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.083594</td>\n",
              "      <td>0.122700</td>\n",
              "      <td>0.164604</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.128318</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.094261</td>\n",
              "      <td>0.134777</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.127072</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.134980</td>\n",
              "      <td>0.198241</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441455</th>\n",
              "      <td>0.201110</td>\n",
              "      <td>0.151725</td>\n",
              "      <td>0.171900</td>\n",
              "      <td>0.056077</td>\n",
              "      <td>0.266355</td>\n",
              "      <td>0.089652</td>\n",
              "      <td>0.112202</td>\n",
              "      <td>0.076920</td>\n",
              "      <td>0.140718</td>\n",
              "      <td>0.173159</td>\n",
              "      <td>0.225517</td>\n",
              "      <td>0.128326</td>\n",
              "      <td>0.164604</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.128318</td>\n",
              "      <td>0.119388</td>\n",
              "      <td>0.094261</td>\n",
              "      <td>0.123972</td>\n",
              "      <td>0.124384</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.127072</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.200757</td>\n",
              "      <td>0.198241</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>441456 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           state  prediabetes       age  ...  employment    sodium  type2_diabetes\n",
              "0       0.169308     0.074352  0.171900  ...    0.292054  0.125268               0\n",
              "1       0.169308     0.074352  0.113065  ...    0.134980  0.098757               0\n",
              "2       0.169308     0.074352  0.218709  ...    0.200757  0.125268               0\n",
              "3       0.169308     0.074352  0.171900  ...    0.292054  0.098757               0\n",
              "4       0.169308     0.074352  0.171900  ...    0.292054  0.198241               0\n",
              "...          ...          ...       ...  ...         ...       ...             ...\n",
              "441451  0.201110     0.151725  0.218709  ...    0.200757  0.198241               1\n",
              "441452  0.201110     0.151725  0.000065  ...    0.070031  0.198241               0\n",
              "441453  0.201110     0.151725  0.218709  ...    0.200757  0.125268               0\n",
              "441454  0.201110     0.151725  0.113065  ...    0.134980  0.198241               0\n",
              "441455  0.201110     0.151725  0.171900  ...    0.200757  0.198241               1\n",
              "\n",
              "[441456 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVmRsPsoP90D",
        "outputId": "bc47c61f-429c-46c8-c454-3e1fd64fd15e"
      },
      "source": [
        "#confirm all missing values are imputed\n",
        "df.columns[df.isnull().any()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9DEGwPOhhxR"
      },
      "source": [
        "# Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoQoY1-oHK0t",
        "outputId": "e541e414-164a-4ccb-ff88-3aa1642dcab8"
      },
      "source": [
        "df['type2_diabetes'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    384708\n",
              "1     56748\n",
              "Name: type2_diabetes, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQw5Hn6DHaEf"
      },
      "source": [
        "1 = 6.77 percent of total observations. This is greater than 5%, which means it is okay to use, but let's address this imbalance with the LightGBM parameter 'sample_pos_weight'. The parameter sample_pos_weight = number of negative samples / number of positive samples. In this case that is sample_pos_weight = 384708 / 56748, which is the 6.77 or 6.8 percent we identified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4YUo-JBc1Bk"
      },
      "source": [
        "#copy of df as appropriate type for LightGBM\n",
        "df1 = df\n",
        "\n",
        "#split data into X and y\n",
        "X,y = df1.drop(['type2_diabetes'], axis = 1), df1['type2_diabetes']\n",
        "#split data 70/30 train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADxmn-fniJGe"
      },
      "source": [
        "# LightGBM ensemble for binary classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giUqfLpiyYzy"
      },
      "source": [
        "The goal of a binary classification problem is to create a machine learning model that makes a prediction in situations where the thing to predict can take one of just two possible values. For this study, we want to predict whether a person is diabetic(1) or not diabetic(2) based on the 24 predictor variables selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPphrHF7mqIr"
      },
      "source": [
        "## baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NjDRnqimzLM"
      },
      "source": [
        "To create a baseline model of the LightGBM algorithm we will use its default parameters to see how it performs on the dataset. We will then evaluate the model using repeated stratified k-fold cross-validation with three repeats and 10 folds. We will report the mean and standard deviation of the accuracy of the model across all repeats and folds.\n",
        "\n",
        "**Note:** Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMf8071FlMOM",
        "outputId": "727ce422-5a03-4819-9d2a-c29b4ea2982b"
      },
      "source": [
        "#define the model\n",
        "model = lgb.LGBMClassifier()\n",
        "\n",
        "#evaluate the model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "#report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.908 (0.001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkFM1gXgn4Z2"
      },
      "source": [
        "We can see from the outcome the LightGBM algorithm with default hyperparameters achieves a **classification accuracy of about 90.8%** on the entire dataset. Therefore, we will use this baseline of performance that we want to out perform. \n",
        "\n",
        "Now, let's see improve the classification accuracy by exploring this algorithm's hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUfkGi-srMpk"
      },
      "source": [
        "## hyperparameter tuning: number of trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t1SBQaesSob"
      },
      "source": [
        "An important hyperparameter for the LightGBM ensemble algorithm is the number of decision trees used in the ensemble.\n",
        "\n",
        "Recall that decision trees are added to the model sequentially in an effort to correct and improve upon the predictions made by prior trees. As such, more trees are often better. The number of trees can be set via the “n_estimators” argument and defaults to 100.\n",
        "\n",
        "The code below explores the effect of the number of trees with values between 10 to 5,000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "NBlbn9ursnut",
        "outputId": "d91c12aa-3777-48b2-ea92-ed0f99273446"
      },
      "source": [
        "#get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\ttrees = [10, 50, 100, 500, 1000, 5000]\n",
        "\tfor n in trees:\n",
        "\t\tmodels[str(n)] = LGBMClassifier(n_estimators=n)\n",
        "\treturn models\n",
        "\n",
        "#evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        "  \n",
        "#get the models to evaluate\n",
        "models = get_models()\n",
        "\n",
        "#evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "\n",
        "#plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">10 0.892 (0.001)\n",
            ">50 0.906 (0.001)\n",
            ">100 0.908 (0.001)\n",
            ">500 0.909 (0.001)\n",
            ">1000 0.908 (0.001)\n",
            ">5000 0.906 (0.001)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehpQq1oIxwdP"
      },
      "source": [
        "From the output we can see that that performance improves on this dataset until about 500 trees, after which performance appears to level off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo9uo31mFkKo"
      },
      "source": [
        "## hyperparameter tuning: tree depth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbYx3h_YFqUH"
      },
      "source": [
        "Varying the depth of each tree added to the ensemble is another important hyperparameter for gradient boosting.\n",
        "\n",
        "The tree depth controls how specialized each tree is to the training dataset: how general or overfit it might be. Tree depth is controlled via the “max_depth” argument and defaults to an unspecified value as the default mechanism for controlling how complex trees are, is to use the number of leaf nodes.\n",
        "\n",
        "There are two main ways to control tree complexity: the max depth of the trees and the maximum number of terminal nodes (leaves) in the tree. In this case, we are exploring the number of leaves so we need to increase the number of leaves to support deeper trees by setting the “num_leaves” argument.\n",
        "\n",
        "The code belows explores tree depths between 1 and 10 and the effect on model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "WCtQGxDfGhbb",
        "outputId": "1eb72625-dfcc-4e43-ee03-ddb99822eec9"
      },
      "source": [
        "#get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(1,11):\n",
        "\t\tmodels[str(i)] = LGBMClassifier(max_depth=i, num_leaves=2**i)\n",
        "\treturn models\n",
        " \n",
        "#evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        " \n",
        "#get the models to evaluate\n",
        "models = get_models()\n",
        "\n",
        "#evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        " \n",
        "#plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">1 0.883 (0.001)\n",
            ">2 0.895 (0.001)\n",
            ">3 0.900 (0.001)\n",
            ">4 0.904 (0.001)\n",
            ">5 0.906 (0.001)\n",
            ">6 0.907 (0.001)\n",
            ">7 0.907 (0.001)\n",
            ">8 0.908 (0.001)\n",
            ">9 0.908 (0.001)\n",
            ">10 0.908 (0.001)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtFkIOf1Gh23"
      },
      "source": [
        "From the output, we can see that performance improves clearly with tree depth to level 8. However, in the box and whisker plot performance appears to slightly continue to improve with tree depth to level 9, after which performance begins to sit reasonably flat.\n",
        "\n",
        "**Note:** the 'num_leaves' parameter was explored as well, resulting in a value of 2^9 = 512 for parameter 'num_leaves' instead of the default value of 31."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-SZiMpeYHmu"
      },
      "source": [
        "## hyperparameter tuning: learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG5U7ltCYON4"
      },
      "source": [
        "Learning rate controls the amount of contribution that each model has on the ensemble prediction. Smaller rates may require more decision trees in the ensemble. The learning rate can be controlled via the “learning_rate” argument and defaults to 0.1.\n",
        "\n",
        "The code below explores the learning rate and compares the effect of values between 0.0001 and 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "ActIZexiYS7u",
        "outputId": "bd567075-5eb0-4beb-ea0c-84ccd9185b65"
      },
      "source": [
        "#get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\trates = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
        "\tfor r in rates:\n",
        "\t\tkey = '%.4f' % r\n",
        "\t\tmodels[key] = LGBMClassifier(learning_rate=r)\n",
        "\treturn models\n",
        " \n",
        "#evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        " \n",
        "#get the models to evaluate\n",
        "models = get_models()\n",
        "\n",
        "#evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        " \n",
        "#plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">0.0001 0.871 (0.000)\n",
            ">0.0010 0.871 (0.000)\n",
            ">0.0100 0.890 (0.001)\n",
            ">0.1000 0.908 (0.001)\n",
            ">1.0000 0.898 (0.012)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzkpKX99ozPP"
      },
      "source": [
        "From the output we can see that a larger learning rate results in better performance on this dataset. In the box and whisker plot we can see the general trend of increasing model performance with the increase in learning rate all the way to the values of 1.0, after which performance appears to level off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPkA419_pr-Q"
      },
      "source": [
        "## hyperparameter tuning: boosting type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhYDDmuXpvkl"
      },
      "source": [
        "A feature of LightGBM is that it supports a number of different boosting algorithms, referred to as boosting types.\n",
        "\n",
        "The boosting type can be specified via the “boosting_type” argument and take a string to specify the type. The options include:\n",
        "\n",
        "- **‘gbdt‘:** Gradient Boosting Decision Tree (GDBT).\n",
        "- **‘dart‘:** Dropouts meet Multiple Additive Regression Trees (DART).\n",
        "- **‘goss‘:** Gradient-based One-Side Sampling (GOSS).\n",
        "\n",
        "The default is GDBT, which is the classical gradient boosting algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "soAktojJqDA-",
        "outputId": "f57c170a-2ad9-4245-fd5f-fd8376404c28"
      },
      "source": [
        "#get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\ttypes = ['gbdt', 'dart', 'goss']\n",
        "\tfor t in types:\n",
        "\t\tmodels[t] = LGBMClassifier(boosting_type=t)\n",
        "\treturn models\n",
        " \n",
        "#evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        " \n",
        "#get the models to evaluate\n",
        "models = get_models()\n",
        "\n",
        "#evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        " \n",
        "#plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">gbdt 0.908 (0.001)\n",
            ">dart 0.905 (0.001)\n",
            ">goss 0.908 (0.001)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRCmmNm8IZwz"
      },
      "source": [
        "From the output we can see that the gbdt and goss boosting method performed equally. However, in the box and whisker plot we can see that the default boosting method (gbdt) performed slightly better than the other two techniques that were evaluated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFRm7yp4ypXO"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRusXY5m-Ido"
      },
      "source": [
        "After establishing a baseline model performance of 90.8% using the default parameters for a LightGBM binary classification model, we were then able to explore hypertuning to improve the performance of the model. After focusing our efforts on the parameters number of trees (n_estimators), tree depth (max_depth), learning rate, and boosting type we were able to confirm the best parameters in terms of performance as 500 (default = 100), 9 (default = -1), 0.1 (default value), and gbdt (default value) respectively. Next, we will build a new LightGBM binary classification model with these parameters and explore it's performance."
      ]
    }
  ]
}